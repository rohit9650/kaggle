{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../working\"))\nprint(os.listdir(\"../input/cats-and-dogs-small/cats_and_dogs_small/cats_and_dogs_small/train\"))\nprint(os.listdir(\"../input/dogs-vs-cats\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44748aa4d4dc20ee534b703ecc46521425e4c958"},"cell_type":"code","source":"# Marking the necessary directories \ntrain_dir = \"../input/cats-and-dogs-small/cats_and_dogs_small/cats_and_dogs_small/train\"\ntrain_cats_dir = os.path.join(train_dir, 'cats')\n\nvalidation_dir = \"../input/cats-and-dogs-small/cats_and_dogs_small/cats_and_dogs_small/validation\"\ntest_dir = \"../input/cats-and-dogs-small/cats_and_dogs_small/cats_and_dogs_small/test\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# model_1\nfrom keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\n\nmodel.add(layers.Conv2D(32, (3,3), activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd507ddb9ce4efdc5577c11569504f501324e353"},"cell_type":"code","source":"# configuring model_1 for training\nfrom keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"146049bd53e0a23ed8c262c6e42f91a84a2206ab"},"cell_type":"code","source":"\"\"\"\nData preprocessing : using ImageDataGenerator to turn image files on disk into \nbatches of preprocessed tensors.\nNote that the generator yields these batches indefinitely:\nit loops endlessly over the images in the target folder\n\"\"\"\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a98d0cbb2b82fab69a7ded97024dbf6732d4426"},"cell_type":"code","source":"# checking the shape of train_generator\nfor data_batch, label_batch in train_generator:\n    print('data batch shape : ', data_batch.shape)\n    print('label batch shape : ', label_batch.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee909dc2c9ef8a5f43949a130aa9199edc1a168e"},"cell_type":"code","source":"#  Fitting the model_1 using a batch generator\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=100,\n                              epochs=30,\n                              validation_data=validation_generator,\n                              validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"094bfa74777949c1f92cdce67ff2b34a499638cf"},"cell_type":"code","source":"# saving model_1\nmodel.save('cats_and_dogs_small_1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ab05ac3c2c21bad8a72f267cb0850ba09bcf4e6","scrolled":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training of model_1\nimport matplotlib.pyplot as plt\n\nacc =  history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55990417608a3914a2174222d42bf247da3eac9e"},"cell_type":"code","source":"\"\"\"\nvalidation accuracy stalls at ~72%, now using 'data augmentation'\nSetting up a data augmentation configuration via ImageDataGenerator\n\"\"\"\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=40,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             fill_mode='nearest')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9609002d0271781876088298ae9f3e03c5ac72ca"},"cell_type":"code","source":"# checking ImageDataGenerator\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\n\nfname = [os.path.join(train_cats_dir, fname) for \n         fname in os.listdir(train_cats_dir)]\n\nimg_path = fname[79]\n\nimg = image.load_img(img_path, target_size=(150, 150))\n\nx = image.img_to_array(img)\nx = x.reshape((1,) + x.shape)\nprint(x.shape)\n\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i%4 == 0:\n        break\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d3985c0a417598c1a16123c8cb8d69ea7feab91"},"cell_type":"code","source":"# model_2 that includes dropout\nfrom keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\n\nmodel.add(layers.Conv2D(32, (3,3), activation='relu',\n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ca30dd39cb0dab377bc6f57a42531e0656921a5"},"cell_type":"code","source":"# configuring model_2 for training\nfrom keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3036d7a743423628b672736674f0d6a781132a"},"cell_type":"code","source":"# Training the model_2 using data-augmentation generators\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=100,\n                              epochs=100,\n                              validation_data=validation_generator,\n                              validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ffd14f4f9359324c3365c64332267912aa60fb"},"cell_type":"code","source":"# saving model_2\nmodel.save('cats_and_dogs_small_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a957b47b63a8ab6dc5ae8b9024f83b91d38dc85"},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training of model_2\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = range(1, len(acc) + 1)\n\nplt.plot(epoch, acc, 'bo', label='Training accuracy')\nplt.plot(epoch, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.legend()\nplt.show()\n\nplt.plot(epoch, loss, 'ro', label='Training loss')\nplt.plot(epoch, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec09b9207c91f7ec5043ec4c813070f977190f5f"},"cell_type":"code","source":"\"\"\"\nUsing a pretrained convnet\nThere are two ways to use a pretrained network: feature extraction and fine-tuning\n\"\"\"\n#  Instantiating the VGG16 convolutional base\nfrom keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22c2214243443cc4235577514df4eb9171a32492"},"cell_type":"code","source":"# summary of VGG16\nconv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06212412414b03313e2849c2818ee2fb68a2ba12"},"cell_type":"code","source":"\"\"\"\nFAST FEATURE EXTRACTION WITHOUT DATA AUGMENTATION\n\"\"\"\n#  Extracting features using the pretrained convolutional base\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20\n\ndef extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(directory,\n                                            target_size=(150, 150),\n                                            batch_size=batch_size,\n                                            class_mode='binary')\n    i=0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i*batch_size:(i+1)*batch_size] = features_batch\n        labels[i * batch_size : (i+1) * batch_size] = labels_batch\n        i+=1\n        if i*batch_size >= sample_count:\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_features, test_labels = extract_features(test_dir, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1d4f9ad65b3d387e925728a504ae6598563909d"},"cell_type":"code","source":"train_features = np.reshape(train_features, (2000, 4*4*512))\nvalidation_features = np.reshape(validation_features, (1000, 4*4*512))\ntest_features = np.reshape(test_features, (1000, 4*4*512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8acdd6da4037bdef62b9dd611709c1d8f41d6e67"},"cell_type":"code","source":"# Defining and training the densely connected classifier model_3\nfrom keras import models, layers, optimizers\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_features,\n                    train_labels,\n                    epochs=30,\n                    batch_size=20,\n                    validation_data=(validation_features, validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d21246ce0d6d48e0f36b5da257edd4610962ddc"},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training of model_3\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = range(1, len(acc) + 1)\n\nplt.plot(epoch, acc, 'bo', label='Training accuracy')\nplt.plot(epoch, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.legend()\nplt.show()\n\nplt.plot(epoch, loss, 'ro', label='Training loss')\nplt.plot(epoch, val_loss, 'r', label='Validation loss')\nplt.title('Trainign and validation loss')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eccf92da8d054626feadbdb7aa6c4ba0c1090693"},"cell_type":"code","source":"\"\"\"\nFEATURE EXTRACTION WITH DATA AUGMENTATION\n\"\"\"\n#  Adding a densely connected classifier on top of the convolutional base model_4\nfrom keras import models, layers\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea96b094e6c22f11bba9dafe35c7dd5c921217fd"},"cell_type":"code","source":"# summary of model_4\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04a28e720841adf3d8f8f639cf334885f3d9017c"},"cell_type":"code","source":"# freezing the conv_base network so that weights don't update\nprint('This is the number of trainable weights '\n'before freezing the conv base:', len(model.trainable_weights))\nconv_base.trainable = False\nprint('This is the number of trainable weights '\n'after freezing the conv base:', len(model.trainable_weights))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ee97b0f1959cbb73e8eac14785483f1f84cd286"},"cell_type":"code","source":"# configuring model_4 for training\nfrom keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0262aa90c37d903ed93225f53ffd34403ac0b900"},"cell_type":"code","source":"#  Training the model_4 end to end with a frozen convolutional base\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=100,\n                              epochs=30,\n                              validation_data=validation_generator,\n                              validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40fcc696968dd35d7d9e74dd22c868930344c204"},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training of model_4\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = range(1, len(acc) + 1)\n\nplt.plot(epoch, acc, 'bo', label='Training accuracy')\nplt.plot(epoch, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.legend()\nplt.show()\n\nplt.plot(epoch, loss, 'ro', label='Training loss')\nplt.plot(epoch, val_loss, 'r', label='Validation loss')\nplt.title('Trainign and validation loss')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c3d315af200cafda7360dd7a4bddf2e0d813b3d"},"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(150, 150),\n                                                  batch_size=20,\n                                                  class_mode='binary')\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f2521ab0e8ac542805132a6494528b63747e478"},"cell_type":"code","source":"conv_base.trainable = True\nset_trainable = False\n\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0420814052d8911b09f399ae5b98517e0b99c665"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=100,\n                              epochs=100,\n                              validation_data=validation_generator,\n                              validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64590ef07a770c47964cb66f99b585f714082882"},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training of model_5\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = range(1, len(acc) + 1)\n\nplt.plot(epoch, acc, 'bo', label='Training accuracy')\nplt.plot(epoch, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.legend()\nplt.show()\n\nplt.plot(epoch, loss, 'ro', label='Training loss')\nplt.plot(epoch, val_loss, 'r', label='Validation loss')\nplt.title('Trainign and validation loss')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8bca9c68e2f7ad7dfa57e9a328dccecf527e8a38"},"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(\ntest_dir,\ntarget_size=(150, 150),\nbatch_size=20,\nclass_mode='binary')\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1d9723b926d5dbe042028de6f0b82d12bbc5054"},"cell_type":"code","source":"testing_dir = \"../input/dogs-vs-cats/test1\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78ddde8623f9d09f13a7fc791f276ff233925c8e"},"cell_type":"code","source":"testing_generator = test_datagen.flow_from_directory(\n    testing_dir,\n    target_size=(150, 150),\n    batch_size=1,\n    shuffle = False,\n    class_mode=None)\n\nfilenames = testing_generator.filenames\nnb_samples = len(filenames)\n\npredict = model.predict_generator(testing_generator)\npredict_class = [1 if pred > 0.5 else 0 for pred in predict]\nprint(len(predict_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e2a2917bf65f061e1b208bdf3042237f6de266b"},"cell_type":"code","source":"#submission = pd.read_csv('../input/dogs-vs-cats/sampleSubmission.csv')\n#submission.to_csv('submission.csv', index=False)\n'''\nout = open('../input/dogs-vs-cats/sampleSubmission.csv', \"w\")\nout.write(\"id,label\\n\")\nrows = ['']*preds.shape[0]\nfor num in range(1,len(predict_class)+1):\n    rows[num]='%d,%d\\n' % (num,preds[num-1])\nout.writelines(rows)\nout.close()\n'''\nids = range(1, 12501)\nmy_submission = pd.DataFrame({'id': ids, 'label': predict_class})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('../working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb10e3b7333232494fee49c6d50704a24675cbe9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}